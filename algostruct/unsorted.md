# Разное

## Асимптотический анализ

Асимтотический анализ показывает порядок роста алгоритма - как увеличивается время работы алгоритма, при увелечении объема входных данных. По факту измеряем не время, а число операций, например - сравнения,присваивания,выделение памяти.Обычно измеряется наихудший случай выполнения, если не оговоренно иное. Записывается, как O(n) (О нотация, О большое) . Примеры:

- Константный — O(1)
- Линейный — O(n)
- Логарифмический — O( log n)
- Линеарифметический — O(n·log n)
- Квадратичный — O(n 2)
- И другие

## Бинарный поиск

Ищет элемент в отсортированном массиве:

1. Определение значения элемента в середине структуры данных. Полученное значение сравнивается с ключом.
2. Если ключ меньше значения середины, то поиск осуществляется в первой половине элементов, иначе — во второй.
3. Поиск сводится к тому, что вновь определяется значение серединного элемента в выбранной половине и сравнивается с ключом.
4. Процесс продолжается до тех пор, пока не будет найден элемент со значением ключа или не станет пустым интервал для поиска.

```php
<?php

function binarySearch( array $arr, int $needle): ?int
{
    $min = 0;
    $max = count($arr) - 1;

    while ($min < $max) {
        
        $middleKey =  floor($min + ($max - $min) / 2);
        $middleVal = $arr[$middleKey];

        if ($needle < $middleVal) {
            $max = $middleKey - 1;
        } elseif ($needle > $middleVal) {
            $min = $middleKey + 1;
        } else {
            return $middleKey;
        }
    }

    return null;
}

$arr = [0,11,22,33,44,55,66,77,88,99];
print_r(binarySearch($arr, 44));
```

## Рекурсия

**Рекурсия** – это когда функция вызывает сама себя(напрямую или через функцию посредника), как правило, с другими аргументами. Рекурсия помогает писать код более компактно и понятно, однако имеет оверхэд по памяти из за необходимости хранить стек вызова. Для оптимизации можно переписать алгоритм используя циклы - любая рекурсия может быть переделана в цикл, как правило, вариант с циклом будет эффективнее.Также есть хвостовая рекурсия.

Хвостовая рекурсия — частный случай рекурсии, при котором любой рекурсивный вызов является последней операцией перед возвратом из функции. Подобный вид рекурсии примечателен тем, что может быть легко заменён на итерацию путём формальной и гарантированно корректной перестройки кода функции. Оптимизация хвостовой рекурсии путём преобразования её в плоскую итерацию реализована во многих оптимизирующих компиляторах. В некоторых функциональных языках программирования спецификация гарантирует обязательную оптимизацию хвостовой рекурсии.

## Разделяй и властвуй

**Разделяй и властвуй**(divide and conquer)  — важная парадигма разработки алгоритмов, заключающаяся в рекурсивном разбиении решаемой задачи на две или более подзадачи того же типа, но меньшего размера, и комбинировании их решений для получения ответа к исходной задаче; разбиения выполняются до тех пор, пока все подзадачи не окажутся элементарными.

Типичный пример — алгоритм сортировки слиянием. Чтобы отсортировать массив чисел по возрастанию, он разбивается на две равные части, каждая сортируется, затем отсортированные части сливаются в одну. Эта процедура применяется к каждой из частей до тех пор, пока сортируемая часть массива содержит хотя бы два элемента (чтобы можно было её разбить на две части). 

## Жадный алгоритм

**Жадный алгоритм** — алгоритм, заключающийся в принятии локально [оптимальных решений](https://ru.wikipedia.org/wiki/%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B5_%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D0%B5) на каждом этапе, допуская, что конечное решение также окажется оптимальным.

Общего критерия оценки применимости жадного алгоритма для решения конкретной задачи не существует, однако для задач, решаемых жадными алгоритмами, характерны две особенности: во-первых, к ним применим *Принцип жадного выбора*, а во-вторых, они обладают свойством *Оптимальности для подзадач*.

- **Принцип жадного выбора**

  Говорят, что к оптимизационной задаче применим **принцип жадного выбора**, если последовательность локально оптимальных выборов даёт глобально оптимальное решение. В типичном случае доказательство оптимальности следует такой схеме:

1. Доказывается, что жадный выбор на первом шаге не закрывает пути к оптимальному решению: для всякого решения есть другое, согласованное с жадным выбором и не хуже первого.
2. Показывается, что подзадача, возникающая после жадного выбора на первом шаге, аналогична исходной.
3. Рассуждение завершается по [индукции](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%B8%D0%BD%D0%B4%D1%83%D0%BA%D1%86%D0%B8%D1%8F).

- **Оптимальность для подзадач**

  Говорят, что задача обладает свойством **оптимальности для подзадач**, если оптимальное решение задачи содержит в себе оптимальные решения для всех её подзадач.